import cron from "node-cron";
import { AppDataSource } from "../config/database";
import { Job, JobStatus, JobChange, ChangeType, Company } from "../entities";
import { logger } from "./logger";

// åŠ¨æ€å¯¼å…¥çˆ¬è™«æ¨¡å—ï¼ˆé¿å…å¾ªç¯ä¾èµ–ï¼‰ã€‚ä½¿ç”¨ runtime require é¿å… TypeScript åœ¨ç¼–è¯‘æœŸè§£æåˆ°å¤–éƒ¨è·¯å¾„ã€‚
async function importCrawler(): Promise<any> {
    try {
        // ä½¿ç”¨å˜é‡çš„è·¯å¾„ï¼Œé¿å… TypeScript åœ¨ç¼–è¯‘æ—¶è§£æå¯¼å…¥
        // eslint-disable-next-line @typescript-eslint/no-var-requires
        const path = "../../crawler/src/adapters";
        // @ts-ignore
        const mod = require(path);
        return mod;
    } catch (err) {
        return {
            getAdapter: (code: string) => undefined,
            getRegisteredCompanies: () => [],
        };
    }
}

/**
 * åŒæ­¥çˆ¬å–ç»“æœåˆ°æ•°æ®åº“
 */
export async function syncJobsToDatabase(
    companyCode: string,
    jobs: Array<{
        postId: string;
        title: string;
        url: string;
        location?: string;
        description?: string;
        requirements?: string;
        salary?: string;
        jobType?: string;
        category?: string;
        tags?: string[];
        postedAt?: Date;
        raw?: Record<string, unknown>;
        contentHash?: string;
    }>
) {
    const jobRepo = AppDataSource.getRepository(Job);
    const changeRepo = AppDataSource.getRepository(JobChange);

    const now = new Date();
    let created = 0;
    let updated = 0;
    let unchanged = 0;

    // è·å–å½“å‰æ•°æ®åº“ä¸­è¯¥å…¬å¸çš„æ‰€æœ‰æ´»è·ƒå²—ä½
    const existingJobs = await jobRepo.find({
        where: { company: companyCode, status: JobStatus.ACTIVE },
    });
    const existingMap = new Map(existingJobs.map((j) => [j.postId, j]));
    const seenPostIds = new Set<string>();

    for (const jobData of jobs) {
        seenPostIds.add(jobData.postId);
        const existing = existingMap.get(jobData.postId);

        if (!existing) {
            // æ–°å¢å²—ä½
            const newJob = jobRepo.create({
                company: companyCode,
                postId: jobData.postId,
                title: jobData.title,
                url: jobData.url,
                location: jobData.location,
                description: jobData.description,
                requirements: jobData.requirements,
                salary: jobData.salary,
                jobType: (jobData.jobType as any) || "intern",
                category: jobData.category,
                tags: jobData.tags,
                postedAt: jobData.postedAt,
                lastCrawledAt: now,
                lastSeenAt: now,
                contentHash: jobData.contentHash,
                raw: jobData.raw,
                status: JobStatus.ACTIVE,
            });

            await jobRepo.save(newJob);

            // è®°å½•å˜æ›´
            await changeRepo.save(
                changeRepo.create({
                    jobId: newJob.id,
                    changeType: ChangeType.CREATED,
                    snapshot: jobData as any,
                })
            );

            created++;
        } else {
            // æ£€æŸ¥æ˜¯å¦æœ‰æ›´æ–°
            const hasChange = existing.contentHash !== jobData.contentHash;

            if (hasChange) {
                // è®°å½•å·®å¼‚
                const diff: Record<string, { old: unknown; new: unknown }> = {};

                if (existing.title !== jobData.title) {
                    diff.title = { old: existing.title, new: jobData.title };
                }
                if (existing.description !== jobData.description) {
                    diff.description = { old: "(changed)", new: "(changed)" };
                }
                if (existing.location !== jobData.location) {
                    diff.location = {
                        old: existing.location,
                        new: jobData.location,
                    };
                }

                // æ›´æ–°å²—ä½
                await jobRepo.update(existing.id, {
                    title: jobData.title,
                    description: jobData.description,
                    requirements: jobData.requirements,
                    location: jobData.location,
                    salary: jobData.salary,
                    category: jobData.category,
                    tags: jobData.tags,
                    lastCrawledAt: now,
                    lastSeenAt: now,
                    contentHash: jobData.contentHash as any,
                    raw: jobData.raw as any,
                } as any);

                // è®°å½•å˜æ›´
                await changeRepo.save(
                    changeRepo.create({
                        jobId: existing.id,
                        changeType: ChangeType.UPDATED,
                        diff,
                    })
                );

                updated++;
            } else {
                // ä»…æ›´æ–°æœ€åå¯è§æ—¶é—´
                await jobRepo.update(existing.id, {
                    lastCrawledAt: now,
                    lastSeenAt: now,
                } as any);
                unchanged++;
            }
        }
    }

    // æ£€æµ‹ä¸‹æ¶çš„å²—ä½ï¼ˆè¿ç»­å¤šæ¬¡æœªå‡ºç°ï¼‰
    const expireThresholdHours = 48; // 48å°æ—¶æœªè§åˆ™æ ‡è®°ä¸ºä¸‹æ¶
    const expireThreshold = new Date(
        now.getTime() - expireThresholdHours * 60 * 60 * 1000
    );

    let expired = 0;
    for (const existing of existingJobs) {
        if (
            !seenPostIds.has(existing.postId) &&
            existing.lastSeenAt < expireThreshold
        ) {
            await jobRepo.update(existing.id, { status: JobStatus.EXPIRED });

            await changeRepo.save(
                changeRepo.create({
                    jobId: existing.id,
                    changeType: ChangeType.REMOVED,
                })
            );

            expired++;
        }
    }

    logger.info(
        `åŒæ­¥å®Œæˆ [${companyCode}]: æ–°å¢=${created}, æ›´æ–°=${updated}, æ— å˜åŒ–=${unchanged}, ä¸‹æ¶=${expired}`
    );

    return { created, updated, unchanged, expired };
}

/**
 * å¯åŠ¨å®šæ—¶çˆ¬å–ä»»åŠ¡
 */
export function startCrawlScheduler(cronExpression: string = "0 */6 * * *") {
    logger.info(`ğŸ“… å¯åŠ¨å®šæ—¶çˆ¬å–ä»»åŠ¡ï¼Œcron: ${cronExpression}`);

    cron.schedule(cronExpression, async () => {
        logger.info("â° å¼€å§‹å®šæ—¶çˆ¬å–ä»»åŠ¡...");

        try {
            const companyRepo = AppDataSource.getRepository(Company);
            const companies = await companyRepo.find({
                where: { enabled: true },
            });

            for (const company of companies) {
                try {
                    const { getAdapter } = await importCrawler();
                    const adapter = getAdapter(company.code);

                    if (!adapter) {
                        logger.warn(`æœªæ‰¾åˆ°å…¬å¸ ${company.code} çš„é€‚é…å™¨`);
                        continue;
                    }

                    logger.info(`å¼€å§‹æŠ“å–: ${company.nameCn || company.name}`);
                    const result = await adapter.crawl();

                    if (result.success) {
                        await syncJobsToDatabase(company.code, result.jobs);
                        await companyRepo.update(company.id, {
                            lastCrawledAt: new Date(),
                        });
                    } else {
                        logger.error(
                            `æŠ“å–å¤±è´¥: ${company.code} - ${result.error}`
                        );
                    }
                } catch (error) {
                    logger.error(`å¤„ç†å…¬å¸ ${company.code} æ—¶å‡ºé”™:`, error);
                }

                // å…¬å¸ä¹‹é—´çš„é—´éš”
                await new Promise((r) => setTimeout(r, 5000));
            }

            logger.info("âœ… å®šæ—¶çˆ¬å–ä»»åŠ¡å®Œæˆ");
        } catch (error) {
            logger.error("å®šæ—¶çˆ¬å–ä»»åŠ¡å¤±è´¥:", error);
        }
    });
}
